{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL solution - Kiss Rita",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOjrbMJtD4cU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj3XhxtsD4cU"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz-g7ncJD4cU"
      },
      "source": [
        "### Getting the data\n",
        "If you have your own dataset,\n",
        "you'll probably want to use the utility\n",
        "`tf.keras.preprocessing.image_dataset_from_directory` to generate similar labeled\n",
        " dataset objects from a set of images on disk filed into class-specific folders.\n",
        "\n",
        "Transfer learning is most useful when working with very small datasets.\n",
        "\n",
        "Here: https://stackoverflow.com/questions/62409838/error-in-loading-image-dataset-from-directory-in-tensorflow, it was suggested to use `flow_from_directory instead`, so I looked it up, and I found it better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVGlJFve4Oaf"
      },
      "source": [
        "#https://www.kaggle.com/general/51898?fbclid=IwAR1MXWo2aPB1HxvR4y0EwU0s7sJaL6uks_pLipHFaCYY6Py2TGPHeOwVLIQ\n",
        "#plugin: https://chrome.google.com/webstore/detail/get-cookiestxt/bgaddhkoddajcdgocldbbfleckgcbcid?hl=hu\n",
        "\n",
        "!wget -x --load-cookies kaggle.com_cookies.txt \"https://www.kaggle.com/c/23035/download-all\" -O data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXXV-NKJYL1P"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DUsgpF3WlPw"
      },
      "source": [
        "#Remove unnecessary files\n",
        "\n",
        "!rm -rf \"/content/NN_2020_Kaggle_dataset/test\"\n",
        "!rm -rf \"/content/NN_2020_Kaggle_dataset/class_id_mapping.py\"\n",
        "!rm -rf \"/content/NN_2020_Kaggle_dataset/Sample_labels_image_id.txt\"\n",
        "\n",
        "#moved test folder manually\n",
        "#!ls \"./NN_2020_Kaggle_dataset/\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nR1x79kD4cU"
      },
      "source": [
        "#kiszedni ami nem kell bele (test mappa, stb...)!\n",
        "DATADIR = \"/content/NN_2020_Kaggle_dataset\"\n",
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 24\n",
        "\n",
        "#https://keras.io/api/preprocessing/image/#flowfromdirectory-method\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        validation_split = 0.2)\n",
        "\n",
        "#don't augment the validation dataset\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split = 0.2)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4tYKzS_aAay",
        "outputId": "08b3c4d7-d73a-49f5-9af0-39fa2e69471c"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATADIR,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed = None,\n",
        "    subset='training') # set as training data"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6711 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUfaleObaIPD",
        "outputId": "0e8ee15c-ce52-4f6b-8419-4c5f49bb15dd"
      },
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    DATADIR,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1669 images belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXCwUZhCD4cV"
      },
      "source": [
        "## Build a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Sj3zTaromNU"
      },
      "source": [
        "from keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from keras.layers import Dense, Dropout, GlobalMaxPooling2D\n",
        "\n",
        "#https://keras.io/api/applications/inceptionresnetv2/ (150, 150, 3) would be one valid value\n",
        "#https://arxiv.org/pdf/1602.07261.pdf\n",
        "\n",
        "def InceptionResNetV2_model(IMG_SIZE, channel = 1, num_classes = None):\n",
        "  \n",
        "  model = InceptionResNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights=\"imagenet\") #néha ez nem működik, mert a colab úgy gondolja, hogy nem szeretné betölteni:)))\n",
        "\n",
        "  x = model.output\n",
        "  x = GlobalMaxPooling2D()(x)\n",
        "  x = Dropout(0.6)(x)\n",
        "  x = Dense(150, activation=\"relu\")(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = Model(model.input, output)\n",
        "\n",
        "#To set 80% of all layers to non-trainable (weights will not be updated)\n",
        "\n",
        "  idx = round(len(model.layers)*0.7)\n",
        "  for layer in model.layers[:idx]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Learning rate is changed to 0.001\n",
        "  sgd = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMCDg-JWoqIz"
      },
      "source": [
        "CHANNEL = 3\n",
        "NUM_CLASSES = 16\n",
        "\n",
        "model2 = InceptionResNetV2_model(IMG_SIZE, CHANNEL, NUM_CLASSES)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohDp4bbYD4cV"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4--kb2bqmuRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c55caf3-27e5-4214-8391-3099cb4ea59e"
      },
      "source": [
        "#Validation accuracy nagyon ugrabugrál, kevesebb epoch is elég lenne talán\n",
        "\n",
        "nb_epochs = 20\n",
        "model2.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // BATCH_SIZE,\n",
        "    epochs = nb_epochs)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "279/279 [==============================] - 56s 201ms/step - loss: 1.7441 - accuracy: 0.4872 - val_loss: 1.2251 - val_accuracy: 0.6147\n",
            "Epoch 2/20\n",
            "279/279 [==============================] - 52s 187ms/step - loss: 0.9154 - accuracy: 0.7084 - val_loss: 1.1498 - val_accuracy: 0.6528\n",
            "Epoch 3/20\n",
            "279/279 [==============================] - 51s 184ms/step - loss: 0.7052 - accuracy: 0.7743 - val_loss: 1.0849 - val_accuracy: 0.6848\n",
            "Epoch 4/20\n",
            "279/279 [==============================] - 51s 183ms/step - loss: 0.6167 - accuracy: 0.8086 - val_loss: 1.0886 - val_accuracy: 0.7023\n",
            "Epoch 5/20\n",
            "279/279 [==============================] - 51s 182ms/step - loss: 0.5300 - accuracy: 0.8382 - val_loss: 1.0943 - val_accuracy: 0.7114\n",
            "Epoch 6/20\n",
            "279/279 [==============================] - 51s 181ms/step - loss: 0.4864 - accuracy: 0.8499 - val_loss: 1.0496 - val_accuracy: 0.7132\n",
            "Epoch 7/20\n",
            "279/279 [==============================] - 50s 180ms/step - loss: 0.4422 - accuracy: 0.8656 - val_loss: 1.0673 - val_accuracy: 0.7168\n",
            "Epoch 8/20\n",
            "279/279 [==============================] - 50s 180ms/step - loss: 0.3836 - accuracy: 0.8783 - val_loss: 1.0802 - val_accuracy: 0.7144\n",
            "Epoch 9/20\n",
            "279/279 [==============================] - 50s 180ms/step - loss: 0.3640 - accuracy: 0.8841 - val_loss: 1.1809 - val_accuracy: 0.7077\n",
            "Epoch 10/20\n",
            "279/279 [==============================] - 50s 180ms/step - loss: 0.3188 - accuracy: 0.9003 - val_loss: 1.1547 - val_accuracy: 0.7240\n",
            "Epoch 11/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.2943 - accuracy: 0.9064 - val_loss: 1.3374 - val_accuracy: 0.7023\n",
            "Epoch 12/20\n",
            "279/279 [==============================] - 50s 179ms/step - loss: 0.2733 - accuracy: 0.9094 - val_loss: 1.1642 - val_accuracy: 0.7313\n",
            "Epoch 13/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.2844 - accuracy: 0.9065 - val_loss: 1.2567 - val_accuracy: 0.7277\n",
            "Epoch 14/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.2644 - accuracy: 0.9179 - val_loss: 1.1436 - val_accuracy: 0.7331\n",
            "Epoch 15/20\n",
            "279/279 [==============================] - 50s 179ms/step - loss: 0.2372 - accuracy: 0.9242 - val_loss: 1.2111 - val_accuracy: 0.7204\n",
            "Epoch 16/20\n",
            "279/279 [==============================] - 50s 179ms/step - loss: 0.2229 - accuracy: 0.9275 - val_loss: 1.2389 - val_accuracy: 0.7252\n",
            "Epoch 17/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.2090 - accuracy: 0.9318 - val_loss: 1.1456 - val_accuracy: 0.7440\n",
            "Epoch 18/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.2072 - accuracy: 0.9367 - val_loss: 1.2952 - val_accuracy: 0.7234\n",
            "Epoch 19/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.1916 - accuracy: 0.9384 - val_loss: 1.3345 - val_accuracy: 0.7385\n",
            "Epoch 20/20\n",
            "279/279 [==============================] - 50s 178ms/step - loss: 0.1846 - accuracy: 0.9411 - val_loss: 1.2762 - val_accuracy: 0.7415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa94a834b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn5CA0u0x0yr"
      },
      "source": [
        "# Test\n",
        "\n",
        "First, I prepared the test images. In order to apply the same `flow_from_directory` method I had to create a new folder that I named `test_data`, and place the `test` folder inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqomN31V4TOw",
        "outputId": "1087a547-04b0-4ffe-c239-61b236f542bb"
      },
      "source": [
        "path = \"/content/test_data\"\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    path,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    batch_size = 1,\n",
        "    class_mode = None,\n",
        "    shuffle = False,\n",
        "    seed=42)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 938 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JxpKqu5oM5e"
      },
      "source": [
        "Prediction with `model.predict()`. I used softmax on the last layer, so I took the index of the maximum value as the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJYpOAMA9NrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cccdcb8-84b5-4f0e-edb2-e5c22c4acc60"
      },
      "source": [
        "#https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "pred = model2.predict(test_generator,\n",
        "                      steps=STEP_SIZE_TEST,\n",
        "                      verbose=1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1/938 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_predict_batch_end` time: 0.0256s). Check your callbacks.\n",
            "938/938 [==============================] - 21s 22ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oWMc-qC-3C1"
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYM_a6LHA9q"
      },
      "source": [
        "#https://stackoverflow.com/questions/41715025/keras-flowfromdirectory-get-file-names-as-they-are-being-generated\n",
        "\n",
        "test_images = []\n",
        "for file in test_generator.filenames:\n",
        "    test_images.append(file[5:])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55xKMsfOHbOc"
      },
      "source": [
        "print(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdHi1mqgo1FZ"
      },
      "source": [
        "Write prediction results to a .txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wMDn05_PdM"
      },
      "source": [
        "with open('last_result.txt', 'w') as new_results:\n",
        "   new_results.write(\"Id,Category\\n\")\n",
        "   for i in range(len(test_images)):\n",
        "     new_results.write(\"%s,%s\\n\" % (test_images[i], predicted_class_indices[i]))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T20ivA1o8aK"
      },
      "source": [
        "Remove the last, unnecessary empty line from the file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF5woLYWDpXJ"
      },
      "source": [
        "fd=open(\"last_result.txt\",\"r\")\n",
        "d=fd.read()\n",
        "fd.close()\n",
        "m=d.split(\"\\n\")\n",
        "s=\"\\n\".join(m[:-1])\n",
        "fd=open(\"last_result.txt\",\"w+\")\n",
        "for i in range(len(s)):\n",
        "    fd.write(s[i])\n",
        "fd.close()"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}